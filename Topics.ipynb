{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2R5wLgv7gZRbwJLMHXVLv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier, early_stopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configuration\n",
        "CSV_URL = \"https://docs.google.com/spreadsheets/d/1fZhDRbXM96enJFXnsP8eRJEVOcQ5agxaapMI9GfW_PQ/export?format=csv\"\n",
        "LAG_CONFIGS = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "MIN_TRAIN_YEARS = 3\n",
        "RANDOM_STATE = 42\n",
        "THRESHOLD_PROB = 0.5\n",
        "PLOT_DIR = \"plots\"\n",
        "TOP_N_FEATURES = 10\n",
        "\n",
        "# Model hyperparameters\n",
        "N_ESTIMATORS_VALIDATION = 200\n",
        "N_ESTIMATORS_FINAL = 300\n",
        "EARLY_STOPPING_ROUNDS = 30\n",
        "\n",
        "# Feature engineering options\n",
        "INCLUDE_ALTERNATE = True\n",
        "STRIDE = 2\n",
        "\n",
        "# Warning thresholds\n",
        "F1_VARIANCE_THRESHOLD = 0.15  # Alert if F1 range exceeds this\n",
        "UNIQUE_PROB_RATIO = 0.5  # Alert if unique probabilities < this ratio\n",
        "\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def load_and_prepare_data(url):\n",
        "    \"\"\"Load data from CSV and convert to long format with binary appear flag.\"\"\"\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    try:\n",
        "        df_wide = pd.read_csv(url)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to load CSV from {url}: {str(e)}\")\n",
        "\n",
        "    if df_wide.empty:\n",
        "        raise ValueError(\"CSV loaded but contains no data\")\n",
        "\n",
        "    df_wide = df_wide.rename(columns={df_wide.columns[0]: 'topic'})\n",
        "\n",
        "    if 'topic' not in df_wide.columns:\n",
        "        raise ValueError(\"CSV must have a 'topic' column\")\n",
        "\n",
        "    # Extract year columns (excluding 'deferred' columns)\n",
        "    year_cols = [col for col in df_wide.columns\n",
        "                 if col != 'topic' and 'deferred' not in str(col).lower()]\n",
        "\n",
        "    if len(year_cols) == 0:\n",
        "        raise ValueError(\"No year columns found in CSV\")\n",
        "\n",
        "    df_wide = df_wide[['topic'] + year_cols]\n",
        "\n",
        "    # Create year mapping - try clean integers first, fallback to regex\n",
        "    year_map = {}\n",
        "    for col in year_cols:\n",
        "        # Try direct integer conversion for clean year columns like \"2015\"\n",
        "        if col.isdigit() and len(col) == 4:\n",
        "            year_map[col] = int(col)\n",
        "        else:\n",
        "            # Fallback to regex for formatted columns like \"Year_2015\"\n",
        "            match = re.search(r'\\d{4}', str(col))\n",
        "            if match:\n",
        "                year_map[col] = int(match.group())\n",
        "\n",
        "    if len(year_map) == 0:\n",
        "        raise ValueError(\"Could not extract year information from columns\")\n",
        "\n",
        "    # Convert to binary appearance\n",
        "    def appeared(cell):\n",
        "        return 0 if pd.isna(cell) or str(cell).strip() == '' else 1\n",
        "\n",
        "    for col in year_cols:\n",
        "        df_wide[col] = df_wide[col].apply(appeared)\n",
        "\n",
        "    # Melt to long format\n",
        "    df = pd.melt(df_wide, id_vars=['topic'], value_vars=year_cols,\n",
        "                 var_name='col', value_name='appear')\n",
        "    df['year'] = df['col'].map(year_map)\n",
        "    df = df[['year', 'topic', 'appear']].dropna().sort_values(['topic', 'year'])\n",
        "    df['year'] = df['year'].astype(int)\n",
        "\n",
        "    # Fill missing year-topic combinations with 0\n",
        "    all_years = np.arange(df['year'].min(), df['year'].max() + 1)\n",
        "    topics = df['topic'].unique()\n",
        "    index = pd.MultiIndex.from_product([topics, all_years], names=['topic', 'year'])\n",
        "    df = df.set_index(['topic', 'year']).reindex(index, fill_value=0).reset_index()\n",
        "    df['appear'] = df['appear'].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def encode_topics(df):\n",
        "    \"\"\"Create topic_id encoding once for consistency.\"\"\"\n",
        "    le = LabelEncoder()\n",
        "    df['topic_id'] = le.fit_transform(df['topic'])\n",
        "    return df, le\n",
        "\n",
        "\n",
        "def build_lag_features(years, values, target_year, n_lags, include_alternate=False, stride=2):\n",
        "    \"\"\"\n",
        "    Pure function to build lag features for a single target year.\n",
        "\n",
        "    Args:\n",
        "        years: Array of historical years\n",
        "        values: Array of historical appearance values (0 or 1)\n",
        "        target_year: Year to predict\n",
        "        n_lags: Number of lag features\n",
        "        include_alternate: Whether to include strided lags\n",
        "        stride: Stride for alternate lags\n",
        "\n",
        "    Returns:\n",
        "        Dict of lag features\n",
        "    \"\"\"\n",
        "    year_to_val = dict(zip(years, values))\n",
        "    features = {}\n",
        "\n",
        "    # Consecutive lags: year-1, year-2, ..., year-n\n",
        "    lag_vals = []\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        val = year_to_val.get(target_year - lag, 0)\n",
        "        features[f'lag_{lag}'] = val\n",
        "        lag_vals.append(val)\n",
        "\n",
        "    features['lag_mean'] = np.mean(lag_vals)\n",
        "\n",
        "    # Alternate (strided) lags: year-stride, year-2*stride, ..., year-n*stride\n",
        "    if include_alternate:\n",
        "        alt_vals = []\n",
        "        for lag in range(1, n_lags + 1):\n",
        "            val = year_to_val.get(target_year - lag * stride, 0)\n",
        "            features[f'alt_lag_{lag}'] = val\n",
        "            alt_vals.append(val)\n",
        "\n",
        "        features['alt_lag_mean'] = np.mean(alt_vals)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def create_features(df, n_lags, include_alternate=False, stride=2):\n",
        "    \"\"\"\n",
        "    Create lag features for all rows in the dataset.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'topic', 'year', 'appear', 'topic_id' columns\n",
        "        n_lags: Number of lag features to create\n",
        "        include_alternate: Whether to include strided lag features\n",
        "        stride: Stride for alternate lags\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with lag features, list of feature column names\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    rows = []\n",
        "\n",
        "    for topic in df['topic'].unique():\n",
        "        topic_data = df[df['topic'] == topic].sort_values('year')\n",
        "        years = topic_data['year'].values\n",
        "        values = topic_data['appear'].values\n",
        "        topic_id = topic_data['topic_id'].iloc[0]\n",
        "\n",
        "        for i, target_year in enumerate(years):\n",
        "            # Build lag features for this year\n",
        "            lag_dict = build_lag_features(\n",
        "                years[:i+1],  # Only use history up to this point\n",
        "                values[:i+1],\n",
        "                target_year,\n",
        "                n_lags,\n",
        "                include_alternate,\n",
        "                stride\n",
        "            )\n",
        "\n",
        "            row = {\n",
        "                'topic': topic,\n",
        "                'year': target_year,\n",
        "                'appear': values[i],\n",
        "                'topic_id': topic_id,\n",
        "                **lag_dict\n",
        "            }\n",
        "            rows.append(row)\n",
        "\n",
        "    df_with_lags = pd.DataFrame(rows)\n",
        "\n",
        "    # Define feature set\n",
        "    lag_cols = [f'lag_{i}' for i in range(1, n_lags + 1)]\n",
        "    features = lag_cols + ['lag_mean', 'year', 'topic_id']\n",
        "\n",
        "    if include_alternate:\n",
        "        alt_cols = [f'alt_lag_{i}' for i in range(1, n_lags + 1)]\n",
        "        features = lag_cols + alt_cols + ['lag_mean', 'alt_lag_mean', 'year', 'topic_id']\n",
        "\n",
        "    return df_with_lags, features\n",
        "\n",
        "\n",
        "def validate_configuration(df, n_lags, features, min_train_years):\n",
        "    \"\"\"\n",
        "    Validate a single lag configuration using time-series cross-validation.\n",
        "\n",
        "    Returns:\n",
        "        List of dicts with validation results for each test year\n",
        "    \"\"\"\n",
        "    min_year = df['year'].min()\n",
        "    available_years = sorted(df['year'].unique())\n",
        "\n",
        "    earliest_test_year = min_year + n_lags + min_train_years\n",
        "    test_years = [y for y in available_years if y >= earliest_test_year]\n",
        "\n",
        "    if len(test_years) == 0:\n",
        "        return []\n",
        "\n",
        "    X = df[features]\n",
        "    y = df['appear']\n",
        "    year_scores = []\n",
        "\n",
        "    for test_year in test_years:\n",
        "        train_idx = df['year'] < test_year\n",
        "        test_idx = df['year'] == test_year\n",
        "\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        train_years_available = df[train_idx]['year'].nunique()\n",
        "\n",
        "        if len(X_test) == 0 or len(X_train) == 0:\n",
        "            continue\n",
        "        if train_years_available < min_train_years:\n",
        "            continue\n",
        "\n",
        "        model = LGBMClassifier(\n",
        "            n_estimators=N_ESTIMATORS_VALIDATION,\n",
        "            random_state=RANDOM_STATE,\n",
        "            verbose=-1\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        year_scores.append({\n",
        "            'year': test_year,\n",
        "            'accuracy': acc,\n",
        "            'f1': f1,\n",
        "            'train_years': train_years_available\n",
        "        })\n",
        "        print(f\"  {test_year}: Acc={acc:.3f}, F1={f1:.3f} \"\n",
        "              f\"(trained on {train_years_available} years)\")\n",
        "\n",
        "    return year_scores\n",
        "\n",
        "\n",
        "def analyze_year_patterns(df, year_scores):\n",
        "    \"\"\"\n",
        "    Analyze why certain years have different F1 scores.\n",
        "    Helps diagnose overfitting vs. genuinely easier/harder years.\n",
        "    \"\"\"\n",
        "    print(\"\\n  Year-by-year analysis:\")\n",
        "    for score in year_scores:\n",
        "        year = score['year']\n",
        "        year_data = df[df['year'] == year]\n",
        "        appearance_rate = year_data['appear'].mean()\n",
        "\n",
        "        # Calculate repeat rate (appeared in previous year)\n",
        "        if year > df['year'].min():\n",
        "            prev_year_data = df[df['year'] == year - 1]\n",
        "            current_topics = set(year_data[year_data['appear'] == 1]['topic'])\n",
        "            prev_topics = set(prev_year_data[prev_year_data['appear'] == 1]['topic'])\n",
        "            repeat_rate = len(current_topics & prev_topics) / len(current_topics) if current_topics else 0\n",
        "        else:\n",
        "            repeat_rate = 0\n",
        "\n",
        "        print(f\"    {year}: F1={score['f1']:.3f}, \"\n",
        "              f\"appear_rate={appearance_rate:.2f}, \"\n",
        "              f\"repeat_rate={repeat_rate:.2f}\")\n",
        "\n",
        "\n",
        "def run_validation(df, lag_configs, include_alternate, stride):\n",
        "    \"\"\"Run validation across all lag configurations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"VALIDATION: Testing {len(lag_configs)} configurations\")\n",
        "    print(f\"Alternate lags: {'enabled' if include_alternate else 'disabled'} \"\n",
        "          f\"(stride={stride if include_alternate else 'N/A'})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for n_lags in lag_configs:\n",
        "        print(f\"\\nTesting {n_lags}-year lookback\")\n",
        "\n",
        "        df_test, features = create_features(\n",
        "            df.copy(), n_lags,\n",
        "            include_alternate=include_alternate,\n",
        "            stride=stride\n",
        "        )\n",
        "\n",
        "        year_scores = validate_configuration(\n",
        "            df_test, n_lags, features, MIN_TRAIN_YEARS\n",
        "        )\n",
        "\n",
        "        if len(year_scores) == 0:\n",
        "            print(\"  Skipped - insufficient data\")\n",
        "            continue\n",
        "\n",
        "        avg_acc = np.mean([s['accuracy'] for s in year_scores])\n",
        "        avg_f1 = np.mean([s['f1'] for s in year_scores])\n",
        "        std_f1 = np.std([s['f1'] for s in year_scores])\n",
        "        min_f1 = min([s['f1'] for s in year_scores])\n",
        "        max_f1 = max([s['f1'] for s in year_scores])\n",
        "\n",
        "        print(f\"  Average: Acc={avg_acc:.3f}, F1={avg_f1:.3f} (±{std_f1:.3f})\")\n",
        "        print(f\"  Range: F1 min={min_f1:.3f}, max={max_f1:.3f}\")\n",
        "        print(f\"  Validated on {len(year_scores)} years\")\n",
        "\n",
        "        all_results.append({\n",
        "            'n_lags': n_lags,\n",
        "            'avg_acc': avg_acc,\n",
        "            'avg_f1': avg_f1,\n",
        "            'std_f1': std_f1,\n",
        "            'min_f1': min_f1,\n",
        "            'max_f1': max_f1,\n",
        "            'n_years_tested': len(year_scores),\n",
        "            'year_scores': year_scores\n",
        "        })\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "def train_final_model(df, best_config, include_alternate, stride):\n",
        "    \"\"\"Train final model on all available data.\"\"\"\n",
        "    print(f\"\\nTraining final model with {best_config}-year lookback\")\n",
        "\n",
        "    df_final, features = create_features(\n",
        "        df.copy(), best_config,\n",
        "        include_alternate=include_alternate,\n",
        "        stride=stride\n",
        "    )\n",
        "\n",
        "    X = df_final[features]\n",
        "    y = df_final['appear']\n",
        "\n",
        "    last_year = df_final['year'].max()\n",
        "    train_idx = df_final['year'] < last_year\n",
        "    test_idx = df_final['year'] == last_year\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=N_ESTIMATORS_FINAL,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    if len(X_test) > 0:\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_test, y_test)],\n",
        "            callbacks=[early_stopping(EARLY_STOPPING_ROUNDS)]\n",
        "        )\n",
        "        pred_test = model.predict(X_test)\n",
        "        print(f\"\\nFinal model performance on {last_year}:\")\n",
        "        print(f\"  Accuracy: {accuracy_score(y_test, pred_test):.3f}\")\n",
        "        print(f\"  F1 Score: {f1_score(y_test, pred_test, zero_division=0):.3f}\")\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        print(\"\\nNo holdout test set available\")\n",
        "\n",
        "    # Feature importance\n",
        "    fi = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(f\"\\nTop {TOP_N_FEATURES} most important features:\")\n",
        "    print(fi.head(TOP_N_FEATURES).to_string(index=False))\n",
        "\n",
        "    return model, df_final, features\n",
        "\n",
        "\n",
        "def predict_next_year(df, best_config, include_alternate, stride, le):\n",
        "    \"\"\"Generate predictions for next year using the pure function approach.\"\"\"\n",
        "    last_year = df['year'].max()\n",
        "    next_year = last_year + 1\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for topic in df['topic'].unique():\n",
        "        topic_data = df[df['topic'] == topic].sort_values('year')\n",
        "        years = topic_data['year'].values\n",
        "        values = topic_data['appear'].values\n",
        "        topic_id = topic_data['topic_id'].iloc[0]\n",
        "\n",
        "        # Build lag features for next year\n",
        "        lag_dict = build_lag_features(\n",
        "            years, values, next_year, best_config,\n",
        "            include_alternate=include_alternate,\n",
        "            stride=stride\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            'topic': topic,\n",
        "            'year': next_year,\n",
        "            'topic_id': topic_id,\n",
        "            **lag_dict\n",
        "        }\n",
        "        predictions.append(row)\n",
        "\n",
        "    return pd.DataFrame(predictions), next_year\n",
        "\n",
        "\n",
        "def save_results(results, all_results, next_year, include_alternate, stride):\n",
        "    \"\"\"Save predictions and validation results to CSV.\"\"\"\n",
        "    # Save predictions\n",
        "    alt_str = f\"alt{int(include_alternate)}_s{stride}\"\n",
        "    filename = f\"LC_CHEMISTRY_{next_year}_PREDICTIONS_{alt_str}.csv\"\n",
        "    results.to_csv(filename, index=False)\n",
        "    print(f\"\\nPredictions saved to {filename}\")\n",
        "\n",
        "    # Save detailed validation\n",
        "    val_records = []\n",
        "    for r in all_results:\n",
        "        for score in r['year_scores']:\n",
        "            val_records.append({\n",
        "                'n_lags': r['n_lags'],\n",
        "                'test_year': score['year'],\n",
        "                'train_years_used': score['train_years'],\n",
        "                'accuracy': score['accuracy'],\n",
        "                'f1': score['f1']\n",
        "            })\n",
        "\n",
        "    val_df = pd.DataFrame(val_records)\n",
        "    val_filename = f\"validation_results_{alt_str}.csv\"\n",
        "    val_df.to_csv(val_filename, index=False)\n",
        "    print(f\"Validation results saved to {val_filename}\")\n",
        "\n",
        "    return val_df\n",
        "\n",
        "\n",
        "def plot_validation_summary(all_results, best_config, include_alternate, stride):\n",
        "    \"\"\"Create compact validation summary plot.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    lags = [r['n_lags'] for r in all_results]\n",
        "    f1s = [r['avg_f1'] for r in all_results]\n",
        "    stds = [r['std_f1'] for r in all_results]\n",
        "    mins = [r['min_f1'] for r in all_results]\n",
        "    maxs = [r['max_f1'] for r in all_results]\n",
        "\n",
        "    # Left: F1 scores with range\n",
        "    ax1.plot(lags, f1s, marker='o', linewidth=2, markersize=8,\n",
        "             label='Average F1', color='#2E86AB')\n",
        "    ax1.fill_between(lags, mins, maxs, alpha=0.2, color='#2E86AB',\n",
        "                      label='Min-Max Range')\n",
        "    ax1.axvline(best_config, color='#A23B72', linestyle='--',\n",
        "                linewidth=2, alpha=0.7, label=f'Best: {best_config} years')\n",
        "    ax1.set_xlabel('Lookback Window (years)', fontsize=11)\n",
        "    ax1.set_ylabel('F1 Score', fontsize=11)\n",
        "    ax1.set_title('Performance vs Lookback Window', fontsize=12, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend()\n",
        "    ax1.set_ylim([0, 1])\n",
        "\n",
        "    # Right: Consistency\n",
        "    ax2.bar(lags, stds, alpha=0.7, color='#F18F01', edgecolor='black', linewidth=1)\n",
        "    ax2.set_xlabel('Lookback Window (years)', fontsize=11)\n",
        "    ax2.set_ylabel('Standard Deviation of F1', fontsize=11)\n",
        "    ax2.set_title('Model Consistency (Lower = Better)', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    for lag, std in zip(lags, stds):\n",
        "        ax2.text(lag, std, f'{std:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    alt_str = f\"alt{int(include_alternate)}_s{stride}\"\n",
        "    filename = f'validation_summary_{alt_str}.png'\n",
        "    plt.savefig(os.path.join(PLOT_DIR, filename), dpi=150, bbox_inches='tight')\n",
        "    print(f\"Validation plot saved to plots/{filename}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load and prepare data\n",
        "    df = load_and_prepare_data(CSV_URL)\n",
        "    df, le = encode_topics(df)\n",
        "\n",
        "    min_year = df['year'].min()\n",
        "    max_year = df['year'].max()\n",
        "    print(f\"Data spans: {min_year} to {max_year} ({max_year - min_year + 1} years)\")\n",
        "    print(f\"Topics tracked: {df['topic'].nunique()}\")\n",
        "\n",
        "    # Run validation\n",
        "    all_results = run_validation(df, LAG_CONFIGS, INCLUDE_ALTERNATE, STRIDE)\n",
        "\n",
        "    if len(all_results) == 0:\n",
        "        print(\"\\nERROR: No valid configurations found\")\n",
        "        return\n",
        "\n",
        "    # Find best configuration\n",
        "    best_config = max(all_results, key=lambda x: x['avg_f1'])\n",
        "    best_n_lags = best_config['n_lags']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"BEST CONFIGURATION: {best_n_lags}-year lookback\")\n",
        "    print(f\"  Average F1: {best_config['avg_f1']:.4f}\")\n",
        "    print(f\"  Consistency: ±{best_config['std_f1']:.4f}\")\n",
        "    print(f\"  F1 range: [{best_config['min_f1']:.3f}, {best_config['max_f1']:.3f}]\")\n",
        "    print(f\"  Tested on: {best_config['n_years_tested']} years\")\n",
        "\n",
        "    # Check for high variance and diagnose\n",
        "    f1_range = best_config['max_f1'] - best_config['min_f1']\n",
        "    if f1_range > F1_VARIANCE_THRESHOLD:\n",
        "        print(f\"\\n  WARNING: Large F1 variance detected ({f1_range:.3f})\")\n",
        "        print(\"  Model performance varies significantly across years\")\n",
        "        print(\"  Investigating year-specific patterns...\")\n",
        "        analyze_year_patterns(df, best_config['year_scores'])\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Train final model\n",
        "    model, df_final, features = train_final_model(\n",
        "        df, best_n_lags, INCLUDE_ALTERNATE, STRIDE\n",
        "    )\n",
        "\n",
        "    # Generate predictions using pure function approach\n",
        "    pred_df, next_year = predict_next_year(\n",
        "        df, best_n_lags, INCLUDE_ALTERNATE, STRIDE, le\n",
        "    )\n",
        "\n",
        "    # Get probabilities\n",
        "    X_future = pred_df[features]\n",
        "    probs = model.predict_proba(X_future)[:, 1]\n",
        "\n",
        "    # Build results\n",
        "    results = pd.DataFrame({\n",
        "        'topic': pred_df['topic'].values,\n",
        "        'prob_2026': probs,\n",
        "        'WILL_APPEAR': (probs >= THRESHOLD_PROB).astype(int)\n",
        "    })\n",
        "\n",
        "    # Add lag features for reference\n",
        "    for col in [c for c in pred_df.columns if c.startswith('lag_') or c.startswith('alt_lag_')]:\n",
        "        results[col] = pred_df[col].values\n",
        "\n",
        "    results = results.sort_values('prob_2026', ascending=False).reset_index(drop=True)\n",
        "    results['Rank'] = results.index + 1\n",
        "\n",
        "    # Display predictions\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"{next_year} PREDICTIONS\")\n",
        "    print(\"=\"*80)\n",
        "    print(results[['Rank', 'topic', 'prob_2026', 'WILL_APPEAR']].head(20).to_string(index=False))\n",
        "\n",
        "    # Check for suspiciously identical probabilities\n",
        "    unique_probs = results['prob_2026'].nunique()\n",
        "    if unique_probs < len(results) * UNIQUE_PROB_RATIO:\n",
        "        print(f\"\\nNOTE: Only {unique_probs}/{len(results)} unique probabilities\")\n",
        "        print(\"This suggests:\")\n",
        "        print(\"  - Model is using simple rules (e.g., 'appeared every year = 0.99')\")\n",
        "        print(\"  - Consider adding more features or increasing model complexity\")\n",
        "        print(\"  - For more granular predictions, try increasing n_estimators\")\n",
        "\n",
        "        # Show distribution of probabilities\n",
        "        prob_counts = results['prob_2026'].value_counts().head(5)\n",
        "        print(f\"\\n  Most common probabilities:\")\n",
        "        for prob, count in prob_counts.items():\n",
        "            print(f\"    {prob:.4f}: {count} topics\")\n",
        "\n",
        "    # Save everything\n",
        "    val_df = save_results(results, all_results, next_year, INCLUDE_ALTERNATE, STRIDE)\n",
        "    plot_validation_summary(all_results, best_n_lags, INCLUDE_ALTERNATE, STRIDE)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi_1ggQydf4P",
        "outputId": "92c79a4a-9190-43b6-f8b7-019340e1d73b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data spans: 2015 to 2025 (11 years)\n",
            "Topics tracked: 23\n",
            "\n",
            "================================================================================\n",
            "VALIDATION: Testing 9 configurations\n",
            "Alternate lags: enabled (stride=2)\n",
            "================================================================================\n",
            "\n",
            "Testing 2-year lookback\n",
            "  2020: Acc=0.870, F1=0.923 (trained on 5 years)\n",
            "  2021: Acc=0.783, F1=0.872 (trained on 6 years)\n",
            "  2022: Acc=0.826, F1=0.895 (trained on 7 years)\n",
            "  2023: Acc=0.870, F1=0.923 (trained on 8 years)\n",
            "  2024: Acc=0.783, F1=0.865 (trained on 9 years)\n",
            "  2025: Acc=0.826, F1=0.900 (trained on 10 years)\n",
            "  Average: Acc=0.826, F1=0.896 (±0.023)\n",
            "  Range: F1 min=0.865, max=0.923\n",
            "  Validated on 6 years\n",
            "\n",
            "Testing 3-year lookback\n",
            "  2021: Acc=0.826, F1=0.900 (trained on 6 years)\n",
            "  2022: Acc=0.826, F1=0.895 (trained on 7 years)\n",
            "  2023: Acc=0.870, F1=0.923 (trained on 8 years)\n",
            "  2024: Acc=0.783, F1=0.872 (trained on 9 years)\n",
            "  2025: Acc=0.870, F1=0.923 (trained on 10 years)\n",
            "  Average: Acc=0.835, F1=0.903 (±0.019)\n",
            "  Range: F1 min=0.872, max=0.923\n",
            "  Validated on 5 years\n",
            "\n",
            "Testing 4-year lookback\n",
            "  2022: Acc=0.826, F1=0.895 (trained on 7 years)\n",
            "  2023: Acc=0.870, F1=0.923 (trained on 8 years)\n",
            "  2024: Acc=0.783, F1=0.872 (trained on 9 years)\n",
            "  2025: Acc=0.913, F1=0.950 (trained on 10 years)\n",
            "  Average: Acc=0.848, F1=0.910 (±0.029)\n",
            "  Range: F1 min=0.872, max=0.950\n",
            "  Validated on 4 years\n",
            "\n",
            "Testing 5-year lookback\n",
            "  2023: Acc=0.870, F1=0.923 (trained on 8 years)\n",
            "  2024: Acc=0.783, F1=0.872 (trained on 9 years)\n",
            "  2025: Acc=0.957, F1=0.976 (trained on 10 years)\n",
            "  Average: Acc=0.870, F1=0.923 (±0.042)\n",
            "  Range: F1 min=0.872, max=0.976\n",
            "  Validated on 3 years\n",
            "\n",
            "Testing 6-year lookback\n",
            "  2024: Acc=0.783, F1=0.872 (trained on 9 years)\n",
            "  2025: Acc=0.913, F1=0.950 (trained on 10 years)\n",
            "  Average: Acc=0.848, F1=0.911 (±0.039)\n",
            "  Range: F1 min=0.872, max=0.950\n",
            "  Validated on 2 years\n",
            "\n",
            "Testing 7-year lookback\n",
            "  2025: Acc=0.870, F1=0.923 (trained on 10 years)\n",
            "  Average: Acc=0.870, F1=0.923 (±0.000)\n",
            "  Range: F1 min=0.923, max=0.923\n",
            "  Validated on 1 years\n",
            "\n",
            "Testing 8-year lookback\n",
            "  Skipped - insufficient data\n",
            "\n",
            "Testing 9-year lookback\n",
            "  Skipped - insufficient data\n",
            "\n",
            "Testing 10-year lookback\n",
            "  Skipped - insufficient data\n",
            "\n",
            "================================================================================\n",
            "BEST CONFIGURATION: 5-year lookback\n",
            "  Average F1: 0.9235\n",
            "  Consistency: ±0.0424\n",
            "  F1 range: [0.872, 0.976]\n",
            "  Tested on: 3 years\n",
            "================================================================================\n",
            "\n",
            "Training final model with 5-year lookback\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "Early stopping, best iteration is:\n",
            "[67]\tvalid_0's binary_logloss: 0.17344\n",
            "\n",
            "Final model performance on 2025:\n",
            "  Accuracy: 0.957\n",
            "  F1 Score: 0.976\n",
            "\n",
            "Top 10 most important features:\n",
            "     feature  importance\n",
            "    topic_id         238\n",
            "        year         101\n",
            "    lag_mean          60\n",
            "alt_lag_mean          56\n",
            "       lag_3          29\n",
            "       lag_1          19\n",
            "       lag_5          14\n",
            "       lag_2          13\n",
            "       lag_4           6\n",
            "   alt_lag_3           5\n",
            "\n",
            "================================================================================\n",
            "2026 PREDICTIONS\n",
            "================================================================================\n",
            " Rank                                         topic  prob_2026  WILL_APPEAR\n",
            "    1                               Acids and bases   0.992325            1\n",
            "    2                         Atmospheric chemistry   0.992325            1\n",
            "    3                              Atomic structure   0.992325            1\n",
            "    4      Calculations based on chemical equations   0.992325            1\n",
            "    5                          Chemical equilibrium   0.992325            1\n",
            "    6                    Ionic and covalent bonding   0.976378            1\n",
            "    7                         Gas laws and the mole   0.975592            1\n",
            "    8              Hydrocarbons and thermochemistry   0.975592            1\n",
            "    9                 Electronic structure of atoms   0.967644            1\n",
            "   10                                        Metals   0.953556            1\n",
            "   11                             Organic chemistry   0.931700            1\n",
            "   12 Shapes of molecules and intermolecular forces   0.889188            1\n",
            "   13                                         Water   0.889188            1\n",
            "   14                                            pH   0.889188            1\n",
            "   15                             Rates of reaction   0.849014            1\n",
            "   16                       Oxidation and reduction   0.769040            1\n",
            "   17                                 Radioactivity   0.741854            1\n",
            "   18                             Chemical formulas   0.570581            1\n",
            "   19                                      Crystals   0.503732            1\n",
            "   20                    Concentration of solutions   0.152496            0\n",
            "\n",
            "Predictions saved to LC_CHEMISTRY_2026_PREDICTIONS_alt1_s2.csv\n",
            "Validation results saved to validation_results_alt1_s2.csv\n",
            "Validation plot saved to plots/validation_summary_alt1_s2.png\n",
            "\n",
            "================================================================================\n",
            "COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}